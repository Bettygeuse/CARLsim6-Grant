/*!

\page tut7_pti Tutorial 7: Parameter Tuning Interface (PTI)
\tableofcontents
\author Kristofor D. Carlson

\section tut7s1_intro 7.1 Introduction

In this tutorial we introduce the parameter tuning interface and how to tune the weight ranges of a
simple SNN to achieve a particular target firing rate. We will be tuning four parameter values that
represent the weight ranges, and we will use the 
<a href="https://cs.gmu.edu/~eclab/projects/ecj/">ECJ evolutionary computation framework</a>.

We will accomplish this by place our CARLsim model inside a program that accept parameter values on 
`stdin`, runs the model, and then rights fitness values to `stdout`.  This provides an interface that 
allows your CARLsim model to be tuned by external optimization tools such as ECJ.

The layout of the SNN is as follows. We have 10 input excitatory
neurons, 10 regular spiking (RS) excitatory neurons that receive this input, and 10 fast spiking
(FS) izhikevich neurons that receive input from the excitatory RS neurons. Additionally, the
inhibitory group is connected to the RS excitatory group and the RS excitatory group is connected to
itself recurrently. There are therefore 4 connection weight ranges to be tuned. The goal of the
tuning is make the RS excitatory group have an average firing rate of 10 Hz and make the FS
inhibitory group have an average firing rate of 20 Hz.

All the required files are found in the doc/source/tutorial/7_pti/src/ directory. The user is encouraged
to follow along and experiment with the source code found there.

This tutorial assumes:
- ECJ version 28 or greater is installed.  Find it at https://cs.gmu.edu/~eclab/projects/ecj/
- CARLsim 5.0 is installed.

The overview of parameter tuning is as follows. ECJ handles all steps of the evolutionary algorithm
(EA) except for \em fitness \em evaluation which is done by CARLsim through the implementation of an
experiment class function called <tt>run</tt>.


A more in-depth overview of CARLsim and ECJ can be found in \ref ch10_ecj.

\section tut7s2_parameter_file 7.2 The ECJ Parameter File

We'll start by configuring ECJ to optimize our model's parameter's with a simple evolutionary algorithm.

To do so, we'll write a parameter file.  ECJ uses big, centralized parameter files to coordinate the 
interaction of a number of different algorithmic modules.  In this example, we'll implement a (μ, λ)-style 
evolutionary algorithm (i.e., an algorithm that discards the parents at
each generation) that evolves real-valued paramter vectores with Gaussian mutation of each real-valued gene,
one-point crossover, and truncation selection.  You can find the complete example in
<tt>ecj_TuneFiringRates.params</tt>.

The <a href="https://cs.gmu.edu/~eclab/projects/ecj/manual.pdf">ECJ manual</a> is a great resource for 
undertstanding these parameters and how to configure them in more detail.


\subsection Boiler Plate

We'll start by inheriting some boiler plate parameters from a parent file.

\code
parent.0 =                                      $ecj_boiler_plate.params
\endcode

This file contains quite a few standard parameter settings that we typically only alter
in special circumstances—it defines things like the Java classes that manages the algorithm
and population state.

Notice there is a <tt>$</tt> before the filename. This indicates that the location of the 
parent file is specified \em relative to the location of our parameter file.


\subsection Problem

Next, and most importantly, we want to tell ECJ to use an external binary program to compute fitness.  
This is done by configuring the `problem` parameter to point to the `CommandProblem` class.  This is 
a special ECJ fitness function that writes parameters to a program's `stdin` and reads fitness
values back that your model writes to `stdout`.

While we're at it we'll also define `evalthreads`, which controls how many instances of your model program
will be run in parallel.  In this tutorial we're relying on the internal parallelism of a single CARLsim
instance to evaluate many individuals at once, so we'll leave ECJ's `evalthreads` set to 1.

\code
eval.problem =                                  ec.app.command.CommandProblem
eval.problem.command =                          $main_TuneFiringRates
evalthreads = 				                    1
\endcode


\subsection Population 

The next important group of parameters controls the population and the outline of how it evolves.
Here we specify that we want a maximum number of 50 generations.  The `quit-on-run-complete`
parameter toggles whether or not evolution should stop early if a solution with the "ideal" 
fitness is found.  We are tuning a noisy fitness function, however, which sometimes causes
an individual to momentarily appear to have a high fitness by chance—and we don't want to 
stop early when that happens.

\code
generations =				                    50
quit-on-run-complete =			                false
\endcode

Now we'll tell ECJ to general 20 individuals to population the initial population (i.e. the
very first generation, when individuals are generated randomly). It's sometimes a good idea 
to create many individuals in the first generation, because this gives us a chance to find a 
good starting point with random search, before we use evolution to refine it.  After that, 
a (μ, λ) breeder takes over evolution, generating `es.lamda.0` children and selecting `es.mu.0` 
parents at each generation.

\code
pop.subpop.0.size =			                    20
breed =					                        ec.es.MuCommaLambdaBreeder
es.mu.0 = 				                        10
es.lambda.0 =                                   20
\endcode

ECJ has several other breeding strategies available, including a (μ + λ) breeder 
(`ec.es.MuPlusLambdaBreeder`), which treats parents and offspring as a combined population 
(so parents have a chance of surviving multiple generations), and `ec.simple.SimpleBreeder`
(which is like `MuCommaLambdaBreeder`, but is meant to work with other traditional selection 
methods, such as tournament selection).


\subsection Representation

Now we'll add several parameters to define how solutions are represented in the EA.  The first 
three are pretty standard, specifcying that we want to use floating-point vectors of numbers

\code
pop.subpop.0.species =                          ec.vector.FloatVectorSpecies
pop.subpop.0.species.ind =		                ec.vector.DoubleVectorIndividual
pop.subpop.0.species.fitness =		            ec.simple.SimpleFitness
\endcode









<!-- TODO: edit the tutorial below this point! -->

There are four parameter values to be tuned so we set:

\code
pop.subpop.0.species.genome-size =      4
\endcode

We will allow all four weight ranges to be tuned within the same parameter range although each
individual parameter can be given it's own range (see \ref ch10_ecj). The minimum weight value for
each weight is then 0.0005 while the maximum value is 0.5 as shown below:

\code
pop.subpop.0.species.min-gene =         0.0005
pop.subpop.0.species.max-gene =         0.5
\endcode


\subsection Operators


\section tut7s3_experiment_class 7.3 The Experiment Class
We next discuss the CARLsim code found in the experiment class. This code is found in the
main_tuneFiringRatesECJ.cpp file. Users should use this tutorial as template for writing their own
code. First a specific experiment class must be inherited from the base class and default
constructor must be defined.:

\code
class TuneFiringRatesECJExperiment : public Experiment {
public:

TuneFiringRatesECJExperiment() {}
\endcode

After that, the user should only be concerned with writing the <tt>run</tt> member function.

\code
...
void run(const ParameterInstances &parameters, std::ostream &outputStream) const {
	int indiNum = parameters.getNumInstances();

	int poissonGroup[indiNum];
	int excGroup[indiNum];
	int inhGroup[indiNum];
	SpikeMonitor* excMonitor[indiNum];
	SpikeMonitor* inhMonitor[indiNum];
	float excHz[indiNum];
	float inhHz[indiNum];
	float excError[indiNum];
	float inhError[indiNum];
	float fitness[indiNum];
...
\endcode

Notice we can use the parameters object to query how many instances/individuals we have defined in
the ECJ parameter file. Now that we have that value, we manually create arrays neuron groups of size
<tt>indiNum</tt>. In our case we have defined 10 individuals per generation.

Next we create our CARLsim network object and assign the 4 parameter values generated by ECJ to our
10 SNN individuals. We iterate over all 10 individuals and assign them 4 distinct parameters each.

\code
CARLsim* const network = new CARLsim("tuneFiringRatesECJ", GPU_MODE, SILENT);

for(unsigned int i = 0; i < parameters.getNumInstances(); i++) {
	poissonGroup[i] = network->createSpikeGeneratorGroup("poisson", NUM_NEURONS, EXCITATORY_NEURON);
	excGroup[i] = network->createGroup("exc", NUM_NEURONS, EXCITATORY_NEURON);
	inhGroup[i] = network->createGroup("inh", NUM_NEURONS, INHIBITORY_NEURON);

	network->setNeuronParameters(excGroup[i], REG_IZH[0], REG_IZH[1], REG_IZH[2], REG_IZH[3]);
	network->setNeuronParameters(inhGroup[i], FAST_IZH[0], FAST_IZH[1], FAST_IZH[2], FAST_IZH[3]);
	network->setConductances(true,COND_tAMPA,COND_tNMDA,COND_tGABAa,COND_tGABAb);

	network->connect(poissonGroup[i], excGroup[i], "random", RangeWeight(parameters.getParameter(i,0)), 0.5f, RangeDelay(1));
	network->connect(excGroup[i], excGroup[i], "random", RangeWeight(parameters.getParameter(i,1)), 0.5f, RangeDelay(1));
	network->connect(excGroup[i], inhGroup[i], "random", RangeWeight(parameters.getParameter(i,2)), 0.5f, RangeDelay(1));
	network->connect(inhGroup[i], excGroup[i], "random", RangeWeight(parameters.getParameter(i,3)), 0.5f, RangeDelay(1));

}
\endcode

We then setup the SNNs, begin recording their spike data with a SpikeMonitor, and run the SNNs.

\code
...
network->setupNetwork();
...
excMonitor[i] = network->setSpikeMonitor(excGroup[i], "/dev/null");
inhMonitor[i] = network->setSpikeMonitor(inhGroup[i], "/dev/null");

excMonitor[i]->startRecording();
inhMonitor[i]->startRecording();
...
network->runNetwork(runTime,0);
\endcode

Finally we stop recording, get the average firing rate of each group and compute a fitness function
which is output to ECJ using standard Linux streams.

\code
excMonitor[i]->stopRecording();
inhMonitor[i]->stopRecording();

excHz[i] = excMonitor[i]->getPopMeanFiringRate();
inhHz[i] = inhMonitor[i]->getPopMeanFiringRate();

excError[i] = fabs(excHz[i] - EXC_TARGET_HZ);
inhError[i] = fabs(inhHz[i] - INH_TARGET_HZ);

fitness[i] = 1/(excError[i] + inhError[i]);
outputStream << fitness[i] << endl;
\endcode

To compile and run the tuning framework we simply type:

\code
make
./launchCARLsimECJ.sh
\endcode

The simulation should run to completion and output the best fitness each generation.

This results in an ECJ out.stat file that we talk about in the next section.


\section tut7s4_output_files 7.4 ECJ Output Files

The output.stat file generated contains the best fitness for that generation along with the four
parameter values associated with that individual. CARLsim users can then use these parameters for
their tuned SNN models.

\see \ref ch10_ecj

*/
